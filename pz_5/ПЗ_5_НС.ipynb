{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Прогноз символов. RNN"
      ],
      "metadata": {
        "id": "j5Tu-BV3KSuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# импортируем регулярные выражения\n",
        "import re"
      ],
      "metadata": {
        "id": "6wjiVTjyKW44"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "bJQINrKnDqju"
      },
      "outputs": [],
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
        "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SubXLsi5ErEN",
        "outputId": "e9e3d875-a00b-4ecd-9cc6-5e94b963e445"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyD7g4glKVps",
        "outputId": "a2dbe19d-1267-4caa-c42c-6ec172461277"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 34 #33 буквы + пробел"
      ],
      "metadata": {
        "id": "IJD76YJ4E6z0"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "DgiJrgsiIK_x"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сформируем словарь из символов нашего текста"
      ],
      "metadata": {
        "id": "7FidyFm4Vhu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
      ],
      "metadata": {
        "id": "appv1wfpIJvH"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "N1yoi7pGId-n"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJmXPaQbIf-I",
        "outputId": "9060aba6-76c4-4ecc-b76f-1b64aaf4950b"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем текст в набор OHE-векторов"
      ],
      "metadata": {
        "id": "f2oVbReOOYpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_chars = 6 #\n",
        "data = tokenizer.texts_to_matrix(text)"
      ],
      "metadata": {
        "id": "1wWs_206JRu-"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev7JPXSPbDB7",
        "outputId": "4be03052-528a-40fc-d350-67d56bdba307"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqy7uBYCJTYV",
        "outputId": "2e0ab35f-232c-4733-a997-634759cf7389"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[inp_chars]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc733c1-50ad-4755-ccad-6689a010f513",
        "id": "kmoMOQbFcHrP"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = data.shape[0]-inp_chars\n",
        "n  #размер обучающего множества (205 - inp_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnWQb42jKAd1",
        "outputId": "1a293fa1-3ef3-4e1c-f9e6-a6060a967e08"
      },
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "kvZ-iB9LKwgc"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:] #предсказание следующего символа"
      ],
      "metadata": {
        "id": "_nG7M5RIKsfs"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z20DCMmSK3tj",
        "outputId": "e195aabb-6138-4db4-fb93-9fbe0201bd0e"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NrELysIK5fL",
        "outputId": "78dbf487-9120-4042-f3cd-b51fe7985090"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbsyrcEGK7G7",
        "outputId": "13006f1f-b89f-48e9-d7e8-fdf9f586c2b8"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDicj8A4cs4o",
        "outputId": "0b95adec-1b15-40d4-c769-71c430f1af01"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(205, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIa7qWTEeDyH",
        "outputId": "155cde42-cfe0-4bdb-9d5f-ecf16202b2b9"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(199, 6, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVq6F608fTJV",
        "outputId": "96eb8479-4fe5-42a2-a2ec-6bc8f46f9a74"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(199, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "lIP7yhRzLZsr"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))\n",
        "model.add(SimpleRNN(500, activation='tanh'))\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwyYcqGiLXPE",
        "outputId": "0d3761e0-eb81-4cf0-fbf5-7129321846d4"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_23 (SimpleRNN)   (None, 500)               267500    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-y2cQiMGLK",
        "outputId": "113926dc-3757-4395-937a-ebb67a28d55f"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 16ms/step - loss: 3.3525 - accuracy: 0.1005\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 2.4926 - accuracy: 0.2563\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 1.9523 - accuracy: 0.5025\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 1.6097 - accuracy: 0.5729\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 1.3355 - accuracy: 0.6432\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.0839 - accuracy: 0.6583\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.9544 - accuracy: 0.7337\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7495 - accuracy: 0.8191\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6532 - accuracy: 0.8392\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6047 - accuracy: 0.8593\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.5218 - accuracy: 0.8643\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.5041 - accuracy: 0.8794\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.4689 - accuracy: 0.8693\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.4142 - accuracy: 0.8945\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.4556 - accuracy: 0.8693\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.4210 - accuracy: 0.8995\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.4575 - accuracy: 0.8794\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3725 - accuracy: 0.8894\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.3045 - accuracy: 0.9497\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2943 - accuracy: 0.9447\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2863 - accuracy: 0.9548\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.2856 - accuracy: 0.9347\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2452 - accuracy: 0.9447\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1713 - accuracy: 0.9799\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1648 - accuracy: 0.9648\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1485 - accuracy: 0.9648\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1176 - accuracy: 0.9849\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1024 - accuracy: 0.9899\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1184 - accuracy: 0.9749\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1205 - accuracy: 0.9698\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0995 - accuracy: 0.9749\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1695 - accuracy: 0.9598\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1927 - accuracy: 0.9598\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2225 - accuracy: 0.9598\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1822 - accuracy: 0.9698\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1489 - accuracy: 0.9548\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1112 - accuracy: 0.9598\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0773 - accuracy: 0.9849\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0818 - accuracy: 0.9849\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0706 - accuracy: 0.9749\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0701 - accuracy: 0.9799\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0659 - accuracy: 0.9899\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0856 - accuracy: 0.9799\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0624 - accuracy: 0.9749\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0742 - accuracy: 0.9799\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1175 - accuracy: 0.9849\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1630 - accuracy: 0.9749\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1032 - accuracy: 0.9849\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0663 - accuracy: 0.9849\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1017 - accuracy: 0.9799\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0717 - accuracy: 0.9799\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1123 - accuracy: 0.9799\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1033 - accuracy: 0.9899\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1076 - accuracy: 0.9698\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1277 - accuracy: 0.9849\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2908 - accuracy: 0.9598\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1312 - accuracy: 0.9598\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3988 - accuracy: 0.9196\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2175 - accuracy: 0.9598\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1415 - accuracy: 0.9698\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2037 - accuracy: 0.9497\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1421 - accuracy: 0.9698\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1161 - accuracy: 0.9749\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0796 - accuracy: 0.9749\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1916 - accuracy: 0.9548\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1933 - accuracy: 0.9648\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1487 - accuracy: 0.9749\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0984 - accuracy: 0.9849\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0956 - accuracy: 0.9849\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0562 - accuracy: 0.9899\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0739 - accuracy: 0.9849\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0499 - accuracy: 0.9950\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0418 - accuracy: 0.9950\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 0.9950\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0269 - accuracy: 0.9950\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 0.9950\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0241 - accuracy: 0.9950\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0220 - accuracy: 0.9950\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0215 - accuracy: 0.9899\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 0.9950\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0215 - accuracy: 0.9950\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 0.9899\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0342 - accuracy: 0.9950\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 0.9950\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9899\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9950\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0199 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 0.9899\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 0.9950\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0186 - accuracy: 0.9950\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0209 - accuracy: 0.9899\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 0.9899\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0287 - accuracy: 0.9849\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9899\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0231 - accuracy: 0.9899\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0274 - accuracy: 0.9899\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 0.9849\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ],
      "metadata": {
        "id": "s0_LNL2pMiku"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-vxdO-dMijp",
        "outputId": "e5fc79b3-08ed-4237-db9c-4257b0881fb6"
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "утренновтовн  и верьте в свою способность достигать отли\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Прогноз слов. RNN.\n"
      ],
      "metadata": {
        "id": "5Lp6XvkoOYyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1.  Попробуйте починить сеть по словам.***"
      ],
      "metadata": {
        "id": "pnfVW0ZctNIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Гипотеза:*** *слишком мало слов, нет слов по которым мы предсказываем продолжение* <br>\n",
        "***Решение:*** *Просто добавим нужные слова в произвольных предложениях.*"
      ],
      "metadata": {
        "id": "pssHth9ftcVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data_my.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '') # убираем первый невидимый символ"
      ],
      "metadata": {
        "id": "_-Wq8QJ2PDM2"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "3oj0eZA4Zs7n",
        "outputId": "c3a03193-ea65-4622-8c2e-d8415fa37b5f"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы — лучший ответ на проблемы, которые возникли в понедельник.\\nДумайте позитивно и верьте в свою способность достигать отличных результатов.\\nЕсли вы смогли в понедельник подняться с постели, значит вы супер герой.\\nЧашка кофе с утра добавляет энергии.\\nГоды бегут, а ничего не меняется.\\nПозитив всегда способствует радости бытия.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавили 3 предложения:\n",
        "* Чашка кофе с утра добавляет энергии.\n",
        "* Годы бегут, а ничего не меняется.\n",
        "* Позитив всегда способствует радости бытия."
      ],
      "metadata": {
        "id": "AcZF3K_FwejN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "maxWordsCount - размер словаря уникальных слов\n"
      ],
      "metadata": {
        "id": "3XiX4wFJKtA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
        "                       lower=True, split=' ', char_level=False)"
      ],
      "metadata": {
        "id": "revghpcNPQSd"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаём словарь уникальных слов"
      ],
      "metadata": {
        "id": "vOw2SQu3jMFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([texts])"
      ],
      "metadata": {
        "id": "VIBLvXtoh4dt"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим, что у нас получилось (частота встречаемости слов)"
      ],
      "metadata": {
        "id": "pi7992bCj2Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dist = list(tokenizer.word_counts.items())\n",
        "print(dist[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPga89Z4PVFe",
        "outputId": "6846b759-ab9a-4eae-9587-0f462ec95a2e"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('вы', 3), ('лучший', 1), ('ответ', 1), ('на', 1), ('проблемы', 1), ('которые', 1), ('возникли', 1), ('в', 3), ('понедельник', 2), ('думайте', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем texts в последовательность чисел из нашего словаря"
      ],
      "metadata": {
        "id": "KqeU6DCSmi0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer.texts_to_sequences([texts])"
      ],
      "metadata": {
        "id": "7mpCwwYQP5hV"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPDrhzF4P7Lk",
        "outputId": "3f390ae1-3bdc-4a77-cbf6-126e469f3f15"
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 2,\n",
              " 3,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 2,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 1,\n",
              " 21,\n",
              " 2,\n",
              " 3,\n",
              " 22,\n",
              " 4,\n",
              " 23,\n",
              " 24,\n",
              " 1,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 4,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42]"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA6DuYkoQS8N",
        "outputId": "3c8c8e9b-19a1-4815-da28-7ac9c06bb17c"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кодируем каждое слово (число) массива data в one-hot векторы"
      ],
      "metadata": {
        "id": "oCeEBxtUm-SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "print( res.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILtfEKKIQH2d",
        "outputId": "51b496b2-203a-4576-d49a-6ef8edd1445a"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получим двумерную матрицу, состоящую из One-hot векторов:"
      ],
      "metadata": {
        "id": "01-Gkl9coB6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res[0]"
      ],
      "metadata": {
        "id": "2t-h9IM4jfO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inp_words - число слов, на основе которых строится прогноз"
      ],
      "metadata": {
        "id": "kyQHYawqLRsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "n = res.shape[0]-inp_words\n",
        "n"
      ],
      "metadata": {
        "id": "pVSmTo2qQyer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82527ae7-9cce-43ff-d967-3095e5063836"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем, из этой матрицы сформируем тензор обучающей выборки и соответствующий набор выходных значений"
      ],
      "metadata": {
        "id": "3vlo_dkjoY9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]"
      ],
      "metadata": {
        "id": "_ljnZUqXQ3Zz"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPmFT4aHoiV8",
        "outputId": "341596c6-b99e-4b4b-b8e6-100e48ac40ba"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 3, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ_HPRR7oluD",
        "outputId": "53469904-6800-46e0-dc89-a49ab273de8d"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(128, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc8dLHkSQ9Nr",
        "outputId": "efcf5a47-d003-43ef-b5db-c312a62e6a50"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_24 (SimpleRNN)   (None, 128)               144512    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273512 (1.04 MB)\n",
            "Trainable params: 273512 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, batch_size=32, epochs=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av36xtecRA8L",
        "outputId": "add884af-d86c-4c71-c83f-f2b9347ed454"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 6.9047 - accuracy: 0.0000e+00\n",
            "Epoch 2/12\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.8645 - accuracy: 0.0889\n",
            "Epoch 3/12\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 6.8279 - accuracy: 0.2222\n",
            "Epoch 4/12\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.7907 - accuracy: 0.4444\n",
            "Epoch 5/12\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.7514 - accuracy: 0.7111\n",
            "Epoch 6/12\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.7083 - accuracy: 0.9111\n",
            "Epoch 7/12\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.6603 - accuracy: 0.9333\n",
            "Epoch 8/12\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.6050 - accuracy: 0.9778\n",
            "Epoch 9/12\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.5399 - accuracy: 0.9778\n",
            "Epoch 10/12\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.4620 - accuracy: 0.9778\n",
            "Epoch 11/12\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.3644 - accuracy: 0.9778\n",
            "Epoch 12/12\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.2401 - accuracy: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(texts, str_len = 20):\n",
        "  res = texts\n",
        "  data = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "    inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "  return res"
      ],
      "metadata": {
        "id": "WiPb0RnqRJiT"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"позитив добавляет годы\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a8f904-d821-421e-fbc1-14cb66313af9",
        "id": "Wq6t3XRCqidj"
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 166ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "позитив добавляет годы радости в в в в в в в в в в в в в в в в в в в\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Сеть по словам починилась!*** <br>\n",
        "***Предсказания немного своеобразные и немного напоминают бред... ***"
      ],
      "metadata": {
        "id": "6GelzHblwrqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2.  Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно более осмысленного текста.***<br>\n",
        "***Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия.*** <br>\n",
        "***Можно использовать текст другого произведения***"
      ],
      "metadata": {
        "id": "nc1n5DJJxCIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Гипотеза:*** *слишком мало слов и предложений для обучения* <br>\n",
        "***Решение:*** *используем более полный текст.*"
      ],
      "metadata": {
        "id": "GZxtrixjycGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data_true.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '') # убираем первый невидимый символ"
      ],
      "metadata": {
        "id": "yn-Bxza-yM4v"
      },
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "e2415ef6-0bbe-4481-e165-0118b061552a",
        "id": "m0VQMLUByM4y"
      },
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Думайте позитивно и верьте в свою способность достигать отличных результатов. \\nВы — лучший ответ на проблемы, которые возникли в понедельник.\\nЕсли вы смогли в понедельник подняться с постели, значит вы супер герой. \\nТвои утренние мысли в понедельник задают тон всей твоей неделе. \\nЖиви так чтобы увидеть, как ты становишься сильнее и живешь счастливой, полноценной жизнью.\\nНе позволяйте утренним проблемам помешать вам быть успешным.\\nТяжелые времена часто приводят к величайшим моментам вашей жизни.\\nПродолжайте двигаться. Трудности в конце концов создают сильных людей.\\nНезависимо через что вы проходите, в конце туннеля есть свет. Может показаться, что добраться до него сложно, но вы сможете сделать это.\\nЧем больше вы настроены позитивно и говорите: я хочу иметь хорошую жизнь, тем больше вы строите для себя эту реальность\\nПринятие позитивного отношения ко всему происходящему может творить чудеса.\\nХорошее настроение добавляет годы к вашей жизни, весну к вашему шагу, искорку в ваших глазах.\\nПриродные способности важны, но вы можете многого достичь и без них, если у вас есть целеустремленность\\nОкружите себя позитивными людьми, которые верят в ваши мечты, поддерживают ваши идеи\\nОставайся позитивным. Прости других. Инвестируй в себя. Доверяй своим инстинктам.\\nНе позволяй другим испортить твой день. Делай вещи, которые приносят тебе радость. Люби себя.\\nИногда лучшее, что ты можешь сделать — это не думать, не удивляться, не воображать, не зацикливаться.\\nПросто дыши и верь, что все получится к лучшему.\\nНе просто учись, а приобретай опыт; не читай, а впитывай. Не просто меняйся, а трансформируйся; не просто связывай, а защищай; не обещай, а докажи.\\nНе критикуй, а поощряй; не просто возьми, а дай; не просто увидь, а почувствуй.\\nНе просто мечтай, а делай; не достаточно услышать, а слушай; не просто расскажи, а покажи.\\nПреданность, вера и позитивное отношение — все это важно, если вы собираетесь добиться успеха\\nВыбор позитивного настроя и благодарного отношения определит, как вы собираетесь прожить свою жизнь.\\nДля меня жизнь заключается в том, чтобы быть позитивным и обнадеживающим, выбирая радость\\nВы можете сделать позитивный выбор на всю оставшуюся жизнь\\nНе тратьте свое время на гнев, сожаления, беспокойства и обиды.\\nЖизнь слишком коротка, чтобы быть несчастной.\\nВсегда верьте в себя и выходите за пределы своих возможностей.\\nВаша жизнь стоит намного больше, чем думаете, потому что вы способны достичь большего, чем знаете.\\nУ вас больше потенциала, чем вам кажется. Но вряд ли вы узнаете весь свой потенциал, если не будете бросать себе вызов\\nЖиви каждый день так, словно твоя жизнь только началась.\\nЕсли вы просто посмотрите на жизнь позитивно, произойдут позитивные вещи.\\nЖизнь становится легче и прекраснее, когда мы видим добро в других людях.\\nЯ беру все негативы в своей жизни и превращаю их в позитив.\\nДержись за свои мечты о лучшей жизни и оставайся приверженным стремлению реализовать это.\\nВы не можете жить позитивной жизнью с негативным умом.\\nЧтобы иметь положительный результат нужно только больше позитива, а от всего остального просто отшутиться.\\nМы все можем привнести позитивную энергию в нашу повседневную жизнь.\\nЕсли будем больше улыбаться, разговаривать с незнакомцами, заменять рукопожатия объятиями и звонить друзьям, просто чтобы сказать им, что мы их любим.\\nЧем меньше вы реагируете на негативных людей, тем более позитивной станет ваша жизнь.\\nКогда вы контролируете свое отношение, вы контролируете свою жизнь.\\nСфокусируйтесь на своих сильных сторонах, а не на слабостях.\\nСосредоточьтесь на своей личности, а не на своей репутации, на своих благословениях, а не на несчастьях.\\nБудьте позитивны с каждой идеей, питающей ваши мечты.\\nПодумайте о возможности того, что вы планируете делать, и подойдите к этому с оптимизмом.\\nОставайтесь на позитиве.\\nВы уникальны! У вас разные таланты и способности. Вам не нужно всегда идти по стопам других.\\nВсегда напоминайте себе, что вам не нужно делать то, что делают все остальные.\\nВы должны развивать таланты, которые были вам даны.\\nСтарайтесь сделать хорошие дни великими и взять что-то положительное из тех дней, когда не чувствуете себя хорошо.\\nБудьте позитивным человеком и продолжайте двигаться вперед.\\nКогда вы просыпаетесь, у вас есть два варианта: быть положительным или отрицательным, оптимистом или пессимистом.\\nПрактически нет ничего невозможного в этом мире, если вы просто сосредоточитесь на цели и сохраните позитивный настрой.\\nНа мгновение отвлекись от проблем и сосредоточься на положительных возможностях.\\nПодумай, как много ты можешь сделать.\\nПобедители в преддверии мероприятия имеют привычку выдвигать свои собственные позитивные ожидания.\\nРаботай усердно ради того, чего хочешь, потому что оно не придет к тебе без боя.\\nТы должен быть сильным и смелым, зная, что можешь делать все, что задумал.\\nЕсли кто-то тебя критикует, просто продолжай верить в себя и превращай это во что-то позитивное.\\nСамая большая стена, на которую вам нужно подняться — это та, которую вы строите в своем уме.\\nНикогда не позволяйте своему разуму отговорить вас от мечты и обманом заставить вас сдаться.\\nНе позволяйте ему стать величайшим препятствием на вашем пути к успеху.\\nНичто не делает человека счастливее, чем счастливое сердце.\\nСкажите и сделайте нечто позитивное, желая помочь ситуации. Чтобы жаловаться, мозги не нужны.\\nИзменения не всегда приносят рост, но без изменений нет роста.\\nНикогда не фокусируйтесь на негативе, а всегда смотрите на позитив.\\nВсегда превращай счастье, боль, печаль и слезы в позитивную энергию.\\nЛибо ты бежишь день, либо день бежит за тобой.\\nБудь позитивным и смейся над всем.\\nКаждый день живи с позитивным настроем и пытайся улучшиться.\\nПозитивное всё — лучше, чем негативное ничего.\\nНикто не идеален — вот почему у карандашей есть ластики.\\nПозитивность всегда побеждает мудрость.\\nСамое главное — смотреть в будущее. Прошлое — это твой якорь.\\nВ глубине своего сердца верьте, что вам суждено совершать великие дела.\\nЧудеса рождаются из убеждений.\\nОдна вещь за один раз. Сначала самое главное. Начинай сейчас.\\nМы ограничены, но мы можем раздвинуть границы наших ограничений.\\nПусть позитив будет вашим вторым именем. Ваша позитивность станет щитом вокруг вас, который защитит вас от стрелы негатива.\\nЕсли вы настроены позитивно, то увидите возможности, а не препятствия.\\nПозитивное мышление и визуализация моего успеха были моими ключами к успеху.\\nТолько хорошее действие в сочетании с позитивным мышлением приводит к успеху.\\nЧтобы создать радугу, нужны солнечный свет и дождь, а без них не было бы радуги.\\nХудшие времена могут стать лучшими, если вы думаете о них с хорошим настроем.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "maxWordsCount - размер словаря уникальных слов\n"
      ],
      "metadata": {
        "id": "xl4ZCc_vyM40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
        "                       lower=True, split=' ', char_level=False)"
      ],
      "metadata": {
        "id": "UB0psiGiyM41"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаём словарь уникальных слов"
      ],
      "metadata": {
        "id": "TynBSITAyM42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([texts])"
      ],
      "metadata": {
        "id": "7iKSSyLHyM43"
      },
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим, что у нас получилось (частота встречаемости слов)"
      ],
      "metadata": {
        "id": "jm2oBZgRyM43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dist = list(tokenizer.word_counts.items())\n",
        "print(dist[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ca6b31-d0c5-4112-fe64-bd5a1c550f93",
        "id": "A8Q-k0KqyM44"
      },
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('думайте', 1), ('позитивно', 4), ('и', 29), ('верьте', 3), ('в', 23), ('свою', 3), ('способность', 1), ('достигать', 1), ('отличных', 1), ('результатов', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем texts в последовательность чисел из нашего словаря"
      ],
      "metadata": {
        "id": "jgh913BwyM45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer.texts_to_sequences([texts])"
      ],
      "metadata": {
        "id": "jy4YnY1CyM46"
      },
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "5JRVC69qyM46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae30412-41cb-48e6-ac15-87dc5e668e24",
        "id": "G7hdN5h2yM47"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "989"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кодируем каждое слово (число) массива data в one-hot векторы"
      ],
      "metadata": {
        "id": "cU2AaOGxyM48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "print( res.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87af18b2-c7fa-447f-c4fd-0e77a33cdb5e",
        "id": "S4_KcQA6yM48"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(989, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получим двумерную матрицу, состоящую из One-hot векторов:"
      ],
      "metadata": {
        "id": "TL8Y17UHyM49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res[0]"
      ],
      "metadata": {
        "id": "BuMv28j6yM49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inp_words - число слов, на основе которых строится прогноз"
      ],
      "metadata": {
        "id": "7Re134xxyM4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "n = res.shape[0]-inp_words\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375974db-36fe-4108-a906-13ad6a3398e6",
        "id": "t4ojrASIyM4-"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "986"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем, из этой матрицы сформируем тензор обучающей выборки и соответствующий набор выходных значений"
      ],
      "metadata": {
        "id": "0k3kJ7mnyM5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]"
      ],
      "metadata": {
        "id": "mUZgoECZyM5E"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b26f9db-2ff1-4b53-9b38-fba1acbea825",
        "id": "CqHi7I4MyM5F"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(986, 3, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d29c32-0455-4485-ef38-c7d2357a2f9e",
        "id": "-DLxhcRIyM5F"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(986, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Input((inp_words, maxWordsCount)))\n",
        "model_1.add(SimpleRNN(128, activation='tanh'))\n",
        "model_1.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model_1.summary()\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1eb8566-4f99-4bb8-f4ea-cf4e49625186",
        "id": "oP95wUYkyM5G"
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_25 (SimpleRNN)   (None, 128)               144512    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273512 (1.04 MB)\n",
            "Trainable params: 273512 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1.fit(X, Y, batch_size=32, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7107cad9-a3e0-45bd-e0d2-296379451164",
        "id": "2GV0exG5yM5G"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 1s 9ms/step - loss: 6.8925 - accuracy: 0.0172\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 6.3697 - accuracy: 0.0680\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 5.8665 - accuracy: 0.0385\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 5.6823 - accuracy: 0.0406\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 5.5204 - accuracy: 0.0578\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 5.3336 - accuracy: 0.0801\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 5.1222 - accuracy: 0.0974\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 4.8504 - accuracy: 0.1318\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 4.5036 - accuracy: 0.1826\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 4.0893 - accuracy: 0.2414\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 3.6306 - accuracy: 0.3458\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 3.1743 - accuracy: 0.4807\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 2.7340 - accuracy: 0.5710\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 2.3321 - accuracy: 0.6420\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.9784 - accuracy: 0.6805\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 1.6870 - accuracy: 0.7231\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.4471 - accuracy: 0.7556\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 1.2602 - accuracy: 0.7880\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.1163 - accuracy: 0.8316\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.0009 - accuracy: 0.8458\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.9081 - accuracy: 0.8702\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.8260 - accuracy: 0.8783\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.7576 - accuracy: 0.8976\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.7060 - accuracy: 0.9047\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6516 - accuracy: 0.9189\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6016 - accuracy: 0.9128\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5641 - accuracy: 0.9270\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5262 - accuracy: 0.9290\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.4908 - accuracy: 0.9229\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.9402\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4282 - accuracy: 0.9422\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4002 - accuracy: 0.9483\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3769 - accuracy: 0.9523\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.9452\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3308 - accuracy: 0.9564\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3131 - accuracy: 0.9513\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.9594\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2750 - accuracy: 0.9716\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2627 - accuracy: 0.9615\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2499 - accuracy: 0.9696\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2345 - accuracy: 0.9635\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2219 - accuracy: 0.9716\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2127 - accuracy: 0.9686\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2027 - accuracy: 0.9736\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1930 - accuracy: 0.9686\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1843 - accuracy: 0.9706\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1769 - accuracy: 0.9757\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1668 - accuracy: 0.9787\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1635 - accuracy: 0.9686\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1540 - accuracy: 0.9757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(texts, str_len = 20):\n",
        "  res = texts\n",
        "  data = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "    inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "    pred = model_1.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "  return res"
      ],
      "metadata": {
        "id": "RVB4ugzZyM5G"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"позитив добавляет годы\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c588dd-0619-4952-c193-70c001007af0",
        "id": "_P0jXnqpyM5H"
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "позитив добавляет годы вторым вашей жизни позитивность двигаться приверженным вокруг вы это защитит на вы стрелы на свою вы нужно на это позитива\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Немного сумбурно, но уже более осмысленно и в целом, что-то в этом есть.<br>***\n",
        "***Такой результат еще связан с очень маленькой обучающей выборкой.***"
      ],
      "metadata": {
        "id": "kks5pZsA1LiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**В Модель 2 добавим Embedding-слой**"
      ],
      "metadata": {
        "id": "UeEvefbD1l4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer.texts_to_sequences([texts])"
      ],
      "metadata": {
        "id": "Xp4FUkgs61Nb"
      },
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве входной обучающей выборки мы теперь можем использовать одномерный массив:"
      ],
      "metadata": {
        "id": "95-gOWkJ-sfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "res = np.array( data[0] )\n",
        "print( res.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1495bf29-1a30-4811-b538-8843e2e03c5d",
        "id": "oWhuXcBs7EYp"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(989,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "n = res.shape[0]-inp_words"
      ],
      "metadata": {
        "id": "QEUJdIFH7EYr"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "А выходные значения остаются прежними – двумерным массивом из One-hot векторов, так как у нас на выходе 1000 нейронов."
      ],
      "metadata": {
        "id": "JRMc-kIL-8EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "X = np.array([res[i:i+inp_words] for i in range(n)])\n",
        "### Y = res[inp_words:]\n",
        "Y = keras.utils.to_categorical(res[inp_words:], num_classes=maxWordsCount)"
      ],
      "metadata": {
        "id": "XVPq-Qqc7EYr"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "### model_2.add(Input((inp_words, maxWordsCount)))\n",
        "model_2.add(Embedding(maxWordsCount, 128, input_length = inp_words))\n",
        "model_2.add(SimpleRNN(128, activation='tanh'))\n",
        "model_2.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model_2.summary()\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a725a3fb-1b3f-471f-8e48-3cdd290ee5da",
        "id": "EjnATiPe7EYs"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 3, 128)            128000    \n",
            "                                                                 \n",
            " simple_rnn_26 (SimpleRNN)   (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289896 (1.11 MB)\n",
            "Trainable params: 289896 (1.11 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее, абсолютно также проводим обучение:"
      ],
      "metadata": {
        "id": "UL4kFJ9p_YCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.fit(X, Y, batch_size=32, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fc0884-e3dd-4777-ccc4-2c33bb011b07",
        "id": "UzTaPxbE8Tw2"
      },
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 2s 8ms/step - loss: 6.8916 - accuracy: 0.0183\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 6.3509 - accuracy: 0.0396\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 5.8296 - accuracy: 0.0598\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 5.5562 - accuracy: 0.0568\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 5.2688 - accuracy: 0.0943\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 4.8863 - accuracy: 0.1227\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 4.4353 - accuracy: 0.1552\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 3.9384 - accuracy: 0.2312\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 3.4567 - accuracy: 0.3499\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 3.0124 - accuracy: 0.5101\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 2.6060 - accuracy: 0.5974\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 2.2359 - accuracy: 0.6643\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 1.9206 - accuracy: 0.7262\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.6396 - accuracy: 0.7718\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.4124 - accuracy: 0.7982\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.2122 - accuracy: 0.8377\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0469 - accuracy: 0.8692\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.9122 - accuracy: 0.8905\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.7999 - accuracy: 0.9138\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.7034 - accuracy: 0.9199\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6230 - accuracy: 0.9381\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.5549 - accuracy: 0.9442\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.9574\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.9635\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.9675\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3597 - accuracy: 0.9726\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.9767\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2948 - accuracy: 0.9797\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2684 - accuracy: 0.9838\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2457 - accuracy: 0.9888\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2289 - accuracy: 0.9807\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.2060 - accuracy: 0.9878\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1899 - accuracy: 0.9868\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1743 - accuracy: 0.9848\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1631 - accuracy: 0.9858\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 0.9899\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1404 - accuracy: 0.9878\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1300 - accuracy: 0.9888\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1217 - accuracy: 0.9848\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1140 - accuracy: 0.9868\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.9858\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.1010 - accuracy: 0.9878\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0961 - accuracy: 0.9868\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0900 - accuracy: 0.9888\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0845 - accuracy: 0.9888\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0809 - accuracy: 0.9888\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9878\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0739 - accuracy: 0.9888\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0706 - accuracy: 0.9878\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 0.9888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "И немного модифицируем функцию buildPhrase:"
      ],
      "metadata": {
        "id": "8DxcK-Dv_TiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(texts, str_len = 20):\n",
        "  res = texts\n",
        "  data = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    ### x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "    ### inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "    x = data[i: i+inp_words]\n",
        "    inp = np.expand_dims(x, axis=0)\n",
        "\n",
        "    pred = model_2.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "\n",
        "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "  return res"
      ],
      "metadata": {
        "id": "139fWATd8Tw4"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"позитив добавляет годы\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671dccb4-55a2-4ec5-9b03-01f327b28ba0",
        "id": "Xul5AYfU-Oxz"
      },
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "позитив добавляет годы свои вашей жизни лучшей к их оставайся оптимизмом человеком других позитиве двигаться себе у вы не таланты жить не вам\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Ещё более осмысленно, что-то в этом есть, но всё же есть сумбурность<br>***"
      ],
      "metadata": {
        "id": "rMJDtjwQ_9JN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Глубокие рекуррентные нейросети"
      ],
      "metadata": {
        "id": "pBLaLgM1AGn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На практике такие модели могут учитывать совсем небольшой прошлый контекст 1-2 слова."
      ],
      "metadata": {
        "id": "r9-p4ZgEFQDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возьмём реализацию для Модели 2"
      ],
      "metadata": {
        "id": "D8BQloXmIs7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer.texts_to_sequences([texts])"
      ],
      "metadata": {
        "id": "pkK9bD6LHNpG"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "res = np.array( data[0] )\n",
        "print( res.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0c2eb8-1cc6-4949-fceb-49cf8fcd8424",
        "id": "5XD6g9-KHNpI"
      },
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(989,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "n = res.shape[0]-inp_words"
      ],
      "metadata": {
        "id": "KlbyzGfRHNpK"
      },
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "X = np.array([res[i:i+inp_words] for i in range(n)])\n",
        "### Y = res[inp_words:]\n",
        "Y = keras.utils.to_categorical(res[inp_words:], num_classes=maxWordsCount)"
      ],
      "metadata": {
        "id": "8hXgJSpgEtIK"
      },
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим ещё один рекуррентный слой <br>\n",
        "Сеть, состоящая из стека двух рекуррентных слоев, будет выглядеть так:"
      ],
      "metadata": {
        "id": "F5HwPGRKFZ7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Embedding(maxWordsCount, 256, input_length = inp_words))\n",
        "model_3.add(SimpleRNN(128, activation='tanh', return_sequences=True))\n",
        "model_3.add(SimpleRNN(64, activation='tanh'))\n",
        "model_3.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oSG8grAAjc3",
        "outputId": "c90e500d-1d66-4912-9f31-def564e854fe"
      },
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 3, 256)            256000    \n",
            "                                                                 \n",
            " simple_rnn_27 (SimpleRNN)   (None, 3, 128)            49280     \n",
            "                                                                 \n",
            " simple_rnn_28 (SimpleRNN)   (None, 64)                12352     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1000)              65000     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 382632 (1.46 MB)\n",
            "Trainable params: 382632 (1.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Всё остальное оставим без изменений"
      ],
      "metadata": {
        "id": "aI_UOECkI_lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "id": "_G_aK85rENyu"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_3.fit(X, Y, batch_size=32, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3582a29e-60aa-4fb6-f7d4-9b03338e1c0d",
        "id": "QXJywLA6CHvd"
      },
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 4s 17ms/step - loss: 6.8817 - accuracy: 0.0183\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 6.2675 - accuracy: 0.0467\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.8207 - accuracy: 0.0436\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.5021 - accuracy: 0.0771\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.1308 - accuracy: 0.1136\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 4.7582 - accuracy: 0.1562\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 4.3978 - accuracy: 0.2323\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 4.0542 - accuracy: 0.3185\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 3.7245 - accuracy: 0.4199\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 3.4187 - accuracy: 0.4797\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 3.1250 - accuracy: 0.5700\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.8481 - accuracy: 0.6268\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5940 - accuracy: 0.6623\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.3551 - accuracy: 0.7110\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.1317 - accuracy: 0.7414\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9262 - accuracy: 0.7819\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.7394 - accuracy: 0.8134\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.5704 - accuracy: 0.8479\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.4162 - accuracy: 0.8712\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.2731 - accuracy: 0.8895\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.1442 - accuracy: 0.9047\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.0285 - accuracy: 0.9118\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.9321 - accuracy: 0.9239\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.8380 - accuracy: 0.9391\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.7551 - accuracy: 0.9452\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6839 - accuracy: 0.9513\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6211 - accuracy: 0.9696\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5659 - accuracy: 0.9686\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5139 - accuracy: 0.9746\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4704 - accuracy: 0.9797\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4311 - accuracy: 0.9777\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3986 - accuracy: 0.9807\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.3665 - accuracy: 0.9848\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.3405 - accuracy: 0.9797\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.3157 - accuracy: 0.9828\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.2959 - accuracy: 0.9848\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.2763 - accuracy: 0.9828\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.2570 - accuracy: 0.9817\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.2402 - accuracy: 0.9878\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2264 - accuracy: 0.9838\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2127 - accuracy: 0.9878\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.2000 - accuracy: 0.9868\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1898 - accuracy: 0.9838\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1804 - accuracy: 0.9878\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1711 - accuracy: 0.9878\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1624 - accuracy: 0.9868\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1544 - accuracy: 0.9878\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1476 - accuracy: 0.9909\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.1428 - accuracy: 0.9838\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.9909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(texts, str_len = 20):\n",
        "  res = texts\n",
        "  data = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    ### x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "    ### inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "    x = data[i: i+inp_words]\n",
        "    inp = np.expand_dims(x, axis=0)\n",
        "\n",
        "    pred = model_3.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "\n",
        "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "  return res"
      ],
      "metadata": {
        "id": "9ukju7MWB6bO"
      },
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"позитив добавляет годы\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ccc3eb-6822-4067-b164-b985ba84ab25",
        "id": "Da7mi7V1B6bQ"
      },
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 425ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "позитив добавляет годы счастье вашей жизни и двигаться приверженным в вы это никогда и вы на в жить а либо не просто день\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z5OfahsrF8sV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Ещё более осмысленная продолжительность текста, но во второй части всё же есть сумбурность<br>***"
      ],
      "metadata": {
        "id": "eMI7Q2ukJPfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ИТОГИ"
      ],
      "metadata": {
        "id": "d3oTQx3FJbxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1.  Попробуйте починить сеть по словам.***"
      ],
      "metadata": {
        "id": "-578z02tF9jK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Гипотеза:*** *слишком мало слов, нет слов по которым мы предсказываем продолжение* <br>\n",
        "***Решение:*** *Просто добавим нужные слова в произвольных предложениях.*"
      ],
      "metadata": {
        "id": "DFXkTWlNF9jL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Сеть по словам (Модель) теперь работает!***"
      ],
      "metadata": {
        "id": "Vx1Zb75QGW-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2.  Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно более осмысленного текста.***<br>\n",
        "***Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия.*** <br>\n",
        "***Можно использовать текст другого произведения***"
      ],
      "metadata": {
        "id": "N0qwPG90GXkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель 1 <br>\n",
        "***Гипотеза:*** *слишком мало слов и предложений для обучения* <br>\n",
        "***Решение:*** *используем более полный текст.*"
      ],
      "metadata": {
        "id": "Fc-VF5aqGXkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В Модель 2 добавим Embedding-слой."
      ],
      "metadata": {
        "id": "2CGUzdBLJ50U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В Модель 3 добавим ещё один рекуррентный слой"
      ],
      "metadata": {
        "id": "fOvIXpwAKOK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Итоги экспериментов:***\n",
        "\n",
        "Модель <br>\n",
        "**позитив добавляет годы радост**и в в в в в в в в в в в в в в в в в в в <br>\n",
        "Модель_1 <br>\n",
        "**позитив добавляет годы вторым вашей жизни** позитивность двигаться приверженным вокруг вы это защитит на вы стрелы на свою вы нужно на это позитива <br>\n",
        "Модель_2 <br>\n",
        "**позитив добавляет годы свои вашей жизни лучшей к их** оставайся оптимизмом человеком других позитиве двигаться себе у вы не таланты жить не вам <br>\n",
        "Модель_3 <br>\n",
        "**позитив добавляет годы счастье вашей жизни и двигаться приверженным в** вы это никогда и вы на в жить а либо не просто день\n"
      ],
      "metadata": {
        "id": "xZcjDWW_KgxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Модель 3 с Embedding-слоем и двумя рекуррентными слоями сгенерировала самую длинную осмысленную цепочку.***"
      ],
      "metadata": {
        "id": "K0Bi8J4COZF2"
      }
    }
  ]
}